{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df27621-ab4d-4a64-b922-81bb35f6f537",
   "metadata": {},
   "source": [
    "# AH ASSESSMENT | DATA ENGINEERING | TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020fccab-b1aa-40a9-8f09-e4602dda36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265499e4-4cc7-4cd8-ad96-2db1f8bb0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,lit,to_date,regexp_replace,regexp_extract, expr\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType,DateType\n",
    "from datetime import datetime,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3abd7f9-e2a3-49a4-9f0c-85fefee17c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49931f0-55ab-4535-bffa-b0ebfa060f93",
   "metadata": {},
   "source": [
    "### INITIALISE SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaae2e98-5111-49a6-ab2f-9e72c2ee97fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/nncube1/Library/Python/3.10/lib/python/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/nncube1/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/nncube1/.ivy2/jars\n",
      "com.crealytics#spark-excel_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-57658128-ace1-40d3-a762-8ced1ed4716d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.crealytics#spark-excel_2.12;0.13.7 in central\n",
      "\tfound org.apache.poi#poi;4.1.2 in central\n",
      "\tfound commons-codec#commons-codec;1.13 in central\n",
      "\tfound org.apache.commons#commons-collections4;4.4 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in central\n",
      "\tfound com.zaxxer#SparseBitSet;1.2 in central\n",
      "\tfound org.apache.poi#poi-ooxml;4.1.2 in central\n",
      "\tfound org.apache.poi#poi-ooxml-schemas;4.1.2 in central\n",
      "\tfound org.apache.xmlbeans#xmlbeans;3.1.0 in central\n",
      "\tfound com.github.virtuald#curvesapi;1.06 in central\n",
      "\tfound com.norbitltd#spoiwo_2.12;1.8.0 in central\n",
      "\tfound org.scala-lang.modules#scala-xml_2.12;1.3.0 in central\n",
      "\tfound com.github.pjfanning#excel-streaming-reader;2.3.6 in central\n",
      "\tfound com.github.pjfanning#poi-shared-strings;1.0.4 in central\n",
      "\tfound com.h2database#h2;1.4.200 in central\n",
      "\tfound org.apache.commons#commons-text;1.8 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.9 in central\n",
      "\tfound xml-apis#xml-apis;1.4.01 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.apache.commons#commons-compress;1.20 in central\n",
      ":: resolution report :: resolve 1812ms :: artifacts dl 65ms\n",
      "\t:: modules in use:\n",
      "\tcom.crealytics#spark-excel_2.12;0.13.7 from central in [default]\n",
      "\tcom.github.pjfanning#excel-streaming-reader;2.3.6 from central in [default]\n",
      "\tcom.github.pjfanning#poi-shared-strings;1.0.4 from central in [default]\n",
      "\tcom.github.virtuald#curvesapi;1.06 from central in [default]\n",
      "\tcom.h2database#h2;1.4.200 from central in [default]\n",
      "\tcom.norbitltd#spoiwo_2.12;1.8.0 from central in [default]\n",
      "\tcom.zaxxer#SparseBitSet;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.13 from central in [default]\n",
      "\torg.apache.commons#commons-collections4;4.4 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.20 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.9 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from central in [default]\n",
      "\torg.apache.commons#commons-text;1.8 from central in [default]\n",
      "\torg.apache.poi#poi;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml;4.1.2 from central in [default]\n",
      "\torg.apache.poi#poi-ooxml-schemas;4.1.2 from central in [default]\n",
      "\torg.apache.xmlbeans#xmlbeans;3.1.0 from central in [default]\n",
      "\torg.scala-lang.modules#scala-xml_2.12;1.3.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\txml-apis#xml-apis;1.4.01 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.commons#commons-compress;1.19 by [org.apache.commons#commons-compress;1.20] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   21  |   0   |   0   |   1   ||   20  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-57658128-ace1-40d3-a762-8ced1ed4716d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 20 already retrieved (0kB/60ms)\n",
      "23/10/11 18:17:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName('AH_ASSESSMENT_TRANSFORM').config(\"spark.jars.packages\",\"com.crealytics:spark-excel_2.12:0.13.7\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97327398-d507-495c-ae6f-64646b575e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.148:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>AH_ASSESSMENT_TRANSFORM</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1103255d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea8c30b-7c83-498e-9a20-c1ca3f7c9561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PYSPARK\n",
    "spark.conf.set(\"spark.sql.legacy.allowUntypedScalaUDF\", \"true\")  # Equivalent to pd.set_option('mode.chained_assignment', None)\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", \"true\")  # Equivalent to pd.set_option('display.max_rows', None)\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.maxNumRows\", 100)  # Equivalent to pd.set_option('display.max_columns', None)\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 0)\n",
    "spark.conf.set(\"zeppelin.spark.printREPLOutput\", \"true\")# Equivalent to pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "#PANDAS\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ead0d-1047-4679-ba1e-c050407fd484",
   "metadata": {},
   "source": [
    "### INGESTING THE FILE FROM THE RAW DATA ZONE FOR TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cfb46d7-412b-486d-8b1e-91d735578db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING LOCATIONS FOR FILEs\n",
    "raw_file_location='1.RAW_DATA_LAYER'\n",
    "transformation_file_location='2.TRANSFORMATION_LAYER'\n",
    "artefact_file_location='4.ARTEFACTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f51ff951-aa50-42d8-9490-c6e3dc05f8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelling_2023-10-04.xlsx']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRACTING THE LIST OF FILES IN THE DIRECTORY\n",
    "source_files = os.listdir(raw_file_location)\n",
    "source_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7560bfe6-d107-4af0-bea4-bdf6869aff30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelling_2023-10-04.xlsx']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if '.DS_Store' in source_files:\n",
    "    file_path = os.path.join(raw_file_location, '.DS_Store')\n",
    "    os.remove(file_path)\n",
    "    \n",
    "source_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee61d93-8dac-4d05-ad3b-47211aed30c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:Error: name 'destination_file_path' is not defined               \n"
     ]
    }
   ],
   "source": [
    "# IF FILE EXISTS,MOVE IT TO THE RAW DATA LAYER,IF NOT THROW AN ERROR.\n",
    "\n",
    "if source_files:\n",
    "    file_name=source_files[0]\n",
    "    source_file_path = os.path.join(raw_file_location, file_name)\n",
    "    try:\n",
    "        df = spark.read.format(\"com.crealytics.spark.excel\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"inferSchema\", \"True\") \\\n",
    "            .option(\"truncate\", \"false\") \\\n",
    "            .load(source_file_path)\n",
    "        logger.info(f\"Successfully moved {file_name} from {source_file_path} to {destination_file_path}.\")\n",
    "\n",
    "        \n",
    "        #lower case columns just in case\n",
    "        df = df.toDF(*[column.lower() for column in df.columns])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {str(e)}\")\n",
    "\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Sorry, no files exist in the folder '{landing_file_location}'.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3373844c-c566-4fd7-98e4-c5600e07ad95",
   "metadata": {},
   "source": [
    "### DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f12e37-f671-4e2a-bc2f-1ead46a3c353",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Sorting out dates | visit_start_date,visit_end_date,pet_dob,dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e00e165-f0a5-4b92-b43b-23856def02dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn(\"visit_start_date\", to_date(col(\"visit_start_date\"), 'dd/MM/yyyy')) \\\n",
    "               .withColumn(\"visit_end_date\", to_date(col(\"visit_end_date\"), 'dd/MM/yyyy')) \\\n",
    "               .withColumn(\"pet_dob\", to_date(col(\"pet_dob\"), 'dd/MM/yyyy')) \\\n",
    "               .withColumn(\"dt\",lit(datetime.now().strftime(\"%Y%m%d\"))) # adding partition date column based on today\n",
    "               #.withColumn(\"dt\",lit(formatted_date))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485aae8a-98f9-4be0-94ce-3c95ea4b85d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Sorting out currency | visit_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7124de8b-5634-4fc0-b3ee-6894b3792373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove non-numeric characters from the visit_cost column and it two decimal places\n",
    "\n",
    "df = df.withColumn(\"visit_cost_numeric\", expr(\"CAST(regexp_replace(visit_cost, '[^0-9.]', '') AS DECIMAL(10,2))\")) \\\n",
    "                  .withColumn(\"currency\", regexp_extract(col(\"visit_cost\"), r'[^\\d.]+', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81c6628f-63bf-4063-b5ec-f0c7f2eb25f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>currency</th><th>count</th></tr>\n",
       "<tr><td>$</td><td>11</td></tr>\n",
       "<tr><td>£</td><td>989</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-----+\n",
       "|currency|count|\n",
       "+--------+-----+\n",
       "|$       |11   |\n",
       "|£       |989  |\n",
       "+--------+-----+"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See distribution of currency\n",
    "count_per_currency = df.groupBy(\"currency\").count()\n",
    "count_per_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d25d72d-e954-457a-b36d-268f71b12174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' QUESTION FOR BUSINESS,WAS THIS PAID WITH FOREIGN CURRENCY OR IS IT A MISTAKE?\\n\\n    IF FOREIGN CURRENCY:\\n        WE NEED TO CONVERT IT FROM $ TO £\\n    IF MISTAKE,WE NEED TO REPLACE $ WITH £ \\n    \\n    Since cities seem made up and $ make up 1.1% of the data,I cannot verify this\\n    For the sake of this assessment,I am just going to assume $ were a mistake'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' QUESTION FOR BUSINESS,WAS THIS PAID WITH FOREIGN CURRENCY OR IS IT A MISTAKE?\n",
    "\n",
    "    IF FOREIGN CURRENCY:\n",
    "        WE NEED TO CONVERT IT FROM $ TO £\n",
    "    IF MISTAKE,WE NEED TO REPLACE $ WITH £ \n",
    "    \n",
    "    Since cities seem made up and $ make up 1.1% of the data,I cannot verify this\n",
    "    For the sake of this assessment,I am just going to assume $ were a mistake'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e25eb0fa-15e9-41b2-ad57-6cbb7a90cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace $ with £\n",
    "df = df.withColumn(\"currency\", regexp_replace(col(\"currency\"), \"\\\\$\", \"£\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d3766d5-1744-4d96-96df-8329505f72e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>currency</th><th>count</th></tr>\n",
       "<tr><td>£</td><td>1000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-----+\n",
       "|currency|count|\n",
       "+--------+-----+\n",
       "|£       |1000 |\n",
       "+--------+-----+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm removal of $\n",
    "count_per_currency = df.groupBy(\"currency\").count()\n",
    "count_per_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2252e941-609e-4a34-bbdd-72dd1c69370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop visit_cost to replace it with the version without currency symbols\n",
    "df=df.drop(\"visit_cost\")\n",
    "df = df.withColumnRenamed(\"visit_cost_numeric\", \"visit_cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412b7ca-88d6-4eae-b0ab-d7cb5c91cdda",
   "metadata": {},
   "source": [
    "### DEFINE DESIRED SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dd33e10-3284-4abe-90f9-6d3ba1756443",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_schema = StructType([\n",
    "    StructField(\"visit_id\", IntegerType(), True),\n",
    "    StructField(\"visit_start_date\", DateType(), True),\n",
    "    StructField(\"visit_end_date\", DateType(), True),\n",
    "    StructField(\"visit_cost\", DoubleType(), True),\n",
    "    StructField(\"currency\", StringType(), True),\n",
    "    StructField(\"procedure_code\", StringType(), True),\n",
    "    StructField(\"procedure_desc\", StringType(), True),\n",
    "    StructField(\"hospital_id\", IntegerType(), True),\n",
    "    StructField(\"hospital\", StringType(), True),\n",
    "    StructField(\"owner_id\", IntegerType(), True),\n",
    "    StructField(\"first_name\", StringType(), True),\n",
    "    StructField(\"last_name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"postcode\", StringType(), True),\n",
    "    StructField(\"pet_id\", IntegerType(), True),\n",
    "    StructField(\"pet_name\", StringType(), True),\n",
    "    StructField(\"species\", StringType(), True),\n",
    "    StructField(\"breed\", StringType(), True),\n",
    "    StructField(\"pet_dob\", DateType(), True),\n",
    "    StructField(\"dt\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f49617eb-7f4e-4486-9c49-a26852e53267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each field,cast data type based on custom schema\n",
    "for field in custom_schema.fields:\n",
    "    df = df.withColumn(field.name, col(field.name).cast(field.dataType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cb00e58-64ea-4f36-8028-290c3bb27f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select desired fields and enforce order\n",
    "\n",
    "df = df.select(\"visit_id\", \"visit_start_date\", \"visit_end_date\", \"currency\",\"visit_cost\", \"procedure_code\", \"procedure_desc\", \"hospital_id\", \"hospital\", \"owner_id\", \"first_name\", \"last_name\", \"email\", \"address\", \"city\", \"postcode\", \"pet_id\", \"pet_name\", \"species\", \"breed\", \"pet_dob\",\"dt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed635c4e-23a6-4f8c-8f6c-f19a4fe504fd",
   "metadata": {},
   "source": [
    "### DATA QUALITY CHECKS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a6684-4eb7-4f16-a8fd-41c3107b6010",
   "metadata": {},
   "source": [
    "##### 1. Duplicate Records - Removing any duplicates records in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9d0ad8a-2a21-4841-8b34-fe54d5d9d6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "duplicate_counts = df.groupBy(df.columns).count().filter('count > 1')\n",
    "duplicates_removed=duplicate_counts.count()\n",
    "\n",
    "if duplicates_removed != 0:\n",
    "    duplicate_output_path = f\"{artefact_file_location}/Duplicates_for_{file_name}.txt\"\n",
    "    print(duplicate_output_path)\n",
    "    \n",
    "    # Saving the count of duplicates to a text file for future reference\n",
    "    with open(duplicate_output_path, 'w') as file:\n",
    "        file.write(f\"Number of Duplicates Removed: {duplicates_removed}\")\n",
    "        logger.info(f\"Number of Duplicated removed saved to {duplicate_output_path}.\")\n",
    "\n",
    "    # Deleting duplicates from df\n",
    "    df = df.dropDuplicates()\n",
    "    logger.info(f\"Duplicates removed\")\n",
    "else:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcbdf8-61d6-4022-8ad2-13f20a7f6cdd",
   "metadata": {},
   "source": [
    "##### 2. Invalid emails - Identify invalid emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534db1c-48fc-4d99-b12d-03704eaa3b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21beba9-551d-48c4-aeb2-b42646386ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9843e89d-b5bf-4800-833a-0463af3a7c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_invalid_emails = df.filter((df[\"email\"].contains(\"@\") == False) & (df[\"email\"] != \"\")).distinct()\n",
    "invalid_emails_path = f\"{artefact_file_location}/Invalid_emails_for_{file_name}.csv\"\n",
    "if df_invalid_emails.count() !=0:\n",
    "    df_invalid_emails.coalesce(1).write.mode(\"overwrite\").csv(invalid_emails_path)\n",
    "    no_invalid_records=df_invalid_emails.count()\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8eef3-3905-49e5-abc2-340d21de8d0c",
   "metadata": {},
   "source": [
    "#### 2. Summary stats for Missing Records,Min and Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2297a7b6-19c5-45d9-ad6b-c3d73b34c320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pandas_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c19a2451-d32f-4f34-a8ee-5ed69899c011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 22)\n"
     ]
    }
   ],
   "source": [
    "total_records = pandas_df.shape\n",
    "print(total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfef060-083f-44f6-bee9-256a4b8189dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_invalid_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c0e93bd-8cc3-4835-b594-f09f46f0107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "Missing Values, Min, and Max:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/pw84ghpj123_713ztc7q6vdc0000gp/T/ipykernel_10513/2611588153.py:7: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  min_values = pandas_df.min().reset_index()\n",
      "/var/folders/d4/pw84ghpj123_713ztc7q6vdc0000gp/T/ipykernel_10513/2611588153.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  max_values = pandas_df.max().reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>data_type</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>visit_id</td>\n",
       "      <td>int32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>currency</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>£</td>\n",
       "      <td>£</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visit_cost</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>26.86</td>\n",
       "      <td>1499.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>procedure_code</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>00BH4ZZ</td>\n",
       "      <td>F06Z3MZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hospital_id</td>\n",
       "      <td>int32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hospital</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>Abbott-Brekke</td>\n",
       "      <td>Wolf-Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>owner_id</td>\n",
       "      <td>int32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>first_name</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Zuzana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>last_name</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>Adnam</td>\n",
       "      <td>todor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>email</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>zroots4l@shinystat.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>address</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>9983 Trailsway Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>city</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Zili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>postcode</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Y3U 2TM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pet_id</td>\n",
       "      <td>int32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pet_name</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Zuzana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>species</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>Arachnid</td>\n",
       "      <td>Rodent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>breed</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>Affenpinscher</td>\n",
       "      <td>Woodpecker, Red-Bellied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dt</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>20231011</td>\n",
       "      <td>20231011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             field data_type  missing_values            min                      max\n",
       "0         visit_id     int32               0              1                     1000\n",
       "1         currency    object               0              £                        £\n",
       "2       visit_cost   float64               0          26.86                  1499.74\n",
       "3   procedure_code    object               0        00BH4ZZ                  F06Z3MZ\n",
       "4      hospital_id     int32               0              1                      100\n",
       "5         hospital    object               0  Abbott-Brekke               Wolf-Smith\n",
       "6         owner_id     int32               0              1                      200\n",
       "7       first_name    object               0                                  Zuzana\n",
       "8        last_name    object               0          Adnam                    todor\n",
       "9            email    object               0                  zroots4l@shinystat.com\n",
       "10         address    object               0                    9983 Trailsway Point\n",
       "11            city    object               0                                    Zili\n",
       "12        postcode    object               0                                 Y3U 2TM\n",
       "13          pet_id     int32               0              1                      200\n",
       "14        pet_name    object               0                                  Zuzana\n",
       "15         species    object               0       Arachnid                   Rodent\n",
       "16           breed    object               0  Affenpinscher  Woodpecker, Red-Bellied\n",
       "17              dt    object               0       20231011                 20231011"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = pandas_df.isnull().sum().reset_index()\n",
    "missing_values.columns = ['field', 'missing_values']\n",
    "# Calculate the minimum and maximum values for each column\n",
    "\n",
    "\n",
    "\n",
    "min_values = pandas_df.min().reset_index()\n",
    "min_values.columns = ['field', 'min']\n",
    "max_values = pandas_df.max().reset_index()\n",
    "max_values.columns = ['field', 'max']\n",
    "\n",
    "data_types = pandas_df.dtypes.reset_index()\n",
    "data_types.columns = ['field', 'data_type']\n",
    "\n",
    "\n",
    "total_records = pandas_df.shape[0]\n",
    "print(total_records)\n",
    "\n",
    "\n",
    "# Merge the DataFrames on the 'field' column\n",
    "result_df = pd.merge(data_types,missing_values, on='field')\n",
    "result_df = pd.merge(result_df, min_values, on='field')\n",
    "result_df = pd.merge(result_df, max_values, on='field')\n",
    "\n",
    "\n",
    "# Show the result\n",
    "print(\"Missing Values, Min, and Max:\")\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab7c44e-737b-4360-8934-02c68fe2c35c",
   "metadata": {},
   "source": [
    "### DIMENSIONAL MODELLING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5696a5ee-2348-4c90-b183-948c9bea7c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit Dimension:\n",
      "root\n",
      " |-- visit_id: integer (nullable = true)\n",
      " |-- visit_start_date: date (nullable = true)\n",
      " |-- visit_end_date: date (nullable = true)\n",
      " |-- visit_cost: double (nullable = true)\n",
      " |-- procedure_code: string (nullable = true)\n",
      " |-- hospital_id: integer (nullable = true)\n",
      " |-- owner_id: integer (nullable = true)\n",
      " |-- pet_id: integer (nullable = true)\n",
      " |-- dt: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a dimension table for Visit\n",
    "visits = df.select(\n",
    "    \"visit_id\",\n",
    "    col(\"visit_start_date\").alias(\"visit_start_date_v\"),  # Alias the column to avoid naming conflicts\n",
    "    col(\"visit_end_date\").alias(\"visit_end_date_v\"), \n",
    "    col(\"currency\"),\n",
    "    col(\"visit_cost\").alias(\"visit_cost_v\"),\n",
    "    col(\"procedure_code\").alias(\"procedure_code_v\"),\n",
    "    col(\"hospital_id\").alias(\"hospital_id_v\"),\n",
    "    col(\"owner_id\").alias(\"owner_id_v\"),\n",
    "    col(\"pet_id\").alias(\"pet_id_v\"),\n",
    "    col(\"dt\").alias(\"dt_v\")\n",
    ").distinct()\n",
    "\n",
    "# Create dimension tables for Procedure, Hospital, Owner, and Pet\n",
    "procedures = df.select(\"procedure_code\", \"procedure_desc\", col(\"dt\").alias(\"dt_p\")).distinct()\n",
    "hospitals = df.select(\"hospital_id\", \"hospital\",col(\"dt\").alias(\"dt_h\")).distinct()\n",
    "owners = df.select(\"owner_id\", \"first_name\", \"last_name\", \"email\", \"address\", \"city\", \"postcode\",col(\"dt\").alias(\"dt_o\")).distinct()\n",
    "pets = df.select(\"pet_id\", \"pet_name\", \"species\", \"breed\", \"pet_dob\",col(\"dt\").alias(\"dt_pt\")).distinct()\n",
    "\n",
    "# Create fact table by joining the dimension tables with the original DataFrame\n",
    "fact_table = df.join(visits, \"visit_id\", \"inner\") \\\n",
    "    .join(procedures, \"procedure_code\", \"inner\") \\\n",
    "    .join(hospitals, \"hospital_id\", \"inner\") \\\n",
    "    .join(owners, \"owner_id\", \"inner\") \\\n",
    "    .join(pets, \"pet_id\", \"inner\") \\\n",
    "    .select(\n",
    "        \"visit_id\",\n",
    "        \"visit_start_date\",\n",
    "        \"visit_end_date\",\n",
    "        \"visit_cost\",\n",
    "        \"procedure_code\",\n",
    "        \"hospital_id\",\n",
    "        \"owner_id\",\n",
    "        \"pet_id\",\n",
    "        \"dt\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Show the resulting DataFrames\n",
    "print(\"Visit Dimension:\")\n",
    "fact_table.printSchema()\n",
    "\n",
    "# print(\"Procedure Dimension:\")\n",
    "# procedures\n",
    "\n",
    "# print(\"Hospital Dimension:\")\n",
    "# hospitals\n",
    "\n",
    "# print(\"Owner Dimension:\")\n",
    "# owners\n",
    "\n",
    "# print(\"Pet Dimension:\")\n",
    "# pets\n",
    "\n",
    "# print(\"Fact Table:\")\n",
    "# fact_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9395bc13-b17e-4eeb-b2bc-b838488a791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RENAME columns for cleaner tables\n",
    "\n",
    "visits = df.select(\n",
    "    \"visit_id\",\n",
    "    col(\"visit_start_date\").alias(\"visit_start_date\"),  # Remove \"_v\"\n",
    "    col(\"visit_end_date\").alias(\"visit_end_date\"), \n",
    "    col(\"currency\"),\n",
    "    col(\"visit_cost\").alias(\"visit_cost\"),\n",
    "    col(\"procedure_code\").alias(\"procedure_code\"),\n",
    "    col(\"hospital_id\").alias(\"hospital_id\"),\n",
    "    col(\"owner_id\").alias(\"owner_id\"),\n",
    "    col(\"pet_id\").alias(\"pet_id\"),\n",
    "    col(\"dt\").alias(\"dt\")\n",
    ").distinct()\n",
    "\n",
    "    \n",
    "\n",
    "procedures = procedures.withColumnRenamed(\"dt_p\", \"dt\")\n",
    "hospitals = hospitals.withColumnRenamed(\"dt_h\", \"dt\")\n",
    "pets = pets.withColumnRenamed(\"dt_pt\", \"dt\")\n",
    "owners = owners.withColumnRenamed(\"dt_o\", \"dt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b03e0d-1c5f-46a2-aa6f-a5bdde7fcc13",
   "metadata": {},
   "source": [
    "##### WRITE INTO THE TRANSFORMATION LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e903c7bf-62ce-498c-b693-a54c6409413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tables = ['visits', 'procedures', 'hospitals', 'owners', 'pets', 'fact_table']\n",
    "\n",
    "for table in tables:\n",
    "    parquet_folder_path = f'{transformation_file_location}/{table}'\n",
    "    today_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    today_partition_path = f'{parquet_folder_path}/dt={today_date}'\n",
    "    visits.write.mode(\"overwrite\").parquet(today_partition_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d31b5b-2d59-4030-9c83-ec46af1fdb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
